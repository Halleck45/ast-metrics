{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"advanced-usage/compare-versions/","title":"Comparing two versions of your code","text":"<p>When you are working on a project, you may want to compare two versions of your code to see how the complexity has evolved over time.</p> <p>With AST Metrics, you can use the <code>--compare-with</code> option to compare two versions of your code.</p> <pre><code>ast-metrics analyze --compare-with=main\n</code></pre> <p>This command will compare the current branch with the <code>main</code> branch. You can replace <code>main</code> with any branch, tag, or commit hash.</p>"},{"location":"advanced-usage/watch-directory/","title":"Watching a directory","text":"<p>It is sometimes convenient to be able to monitor a directory to detect changes in files, without having to rerun the analysis.</p> <p>AST Metrics offers an option to watch a directory and display the results in real time.</p> <p>To watch a directory, run the following command in your terminal:</p> <pre><code>ast-metrics --watch /path/to/your/project\n</code></pre>"},{"location":"ci/deploy-github-org/","title":"Deploy to GitHub Organization","text":"<p>AST Metrics provides a powerful command to automatically deploy AST Metrics to multiple repositories in your GitHub organization with a single command. This feature scans your organization, lets you select which repositories to target, and opens a Pull Request on each selected repository.</p>"},{"location":"ci/deploy-github-org/#how-it-works","title":"How it works","text":"<p>When you run the deployment command:</p> <ol> <li>Scan: AST Metrics scans your GitHub organization for eligible repositories</li> <li>Select: You choose which repositories to deploy to (or select all)</li> <li>Open PRs: A Pull Request is automatically opened on each selected repository</li> <li>You control the merge: The PRs are only opened - you remain in control and decide when to merge them</li> </ol> <p>[!IMPORTANT] The Pull Requests are only opened, not automatically merged. You or your team members will need to review and merge each PR manually. This gives you full control over when AST Metrics is integrated into each repository.</p>"},{"location":"ci/deploy-github-org/#required-github-token-permissions","title":"Required GitHub Token Permissions","text":"<p>To use this feature, you need a GitHub Personal Access Token with the following permissions:</p> <ul> <li><code>repo</code> (write): Required to create branches and commit workflow files</li> <li><code>pull_requests</code> (write): Required to open Pull Requests</li> <li><code>workflows</code> (write): Required to add or modify GitHub Actions workflow files</li> </ul>"},{"location":"ci/deploy-github-org/#creating-a-github-token","title":"Creating a GitHub Token","text":"<ol> <li>Go to GitHub Settings &gt; Developer settings &gt; Personal access tokens &gt; Tokens (classic)</li> <li>Click \"Generate new token\" &gt; \"Generate new token (classic)\"</li> <li>Give your token a descriptive name (e.g., \"AST Metrics Deployment\")</li> <li>Select the following scopes:</li> <li>\u2705 <code>repo</code> (Full control of private repositories)</li> <li>\u2705 <code>workflow</code> (Update GitHub Action workflows)</li> <li>Click \"Generate token\"</li> <li>Copy the token immediately (you won't be able to see it again)</li> </ol>"},{"location":"ci/deploy-github-org/#usage","title":"Usage","text":"<pre><code>ast-metrics deploy:github --token=&lt;github-token&gt; &lt;organization-name&gt;\n</code></pre>"},{"location":"ci/deploy-github-org/#example","title":"Example","text":"<pre><code># Deploy to all or selected repositories in your organization\nast-metrics deploy:github --token=ghp_xxxxxxxxxxxx my-company\n\n# The command will:\n# 1. Scan your organization\n# 2. Show you a list of eligible repositories\n# 3. Let you select which ones to deploy to\n# 4. Open a PR on each selected repository\n</code></pre>"},{"location":"ci/deploy-github-org/#using-environment-variables","title":"Using Environment Variables","text":"<p>You can also set your GitHub token as an environment variable to avoid passing it in the command:</p> <pre><code>export GITHUB_TOKEN=\"your_personal_access_token\"\nast-metrics deploy:github --token=$GITHUB_TOKEN my-company\n</code></pre> <p>Or provide it inline:</p> <pre><code>GITHUB_TOKEN=\"your_personal_access_token\" ast-metrics deploy:github --token=$GITHUB_TOKEN my-company\n</code></pre>"},{"location":"ci/deploy-github-org/#what-gets-added-to-each-repository","title":"What gets added to each repository","text":"<p>The Pull Request will add:</p> <ul> <li>A GitHub Actions workflow file (<code>.github/workflows/ast-metrics.yml</code>)</li> <li>Configuration to run AST Metrics on your codebase</li> <li>Automated quality metrics reporting</li> </ul>"},{"location":"ci/deploy-github-org/#next-steps","title":"Next Steps","text":"<p>After the PRs are opened:</p> <ol> <li>Review each PR: Check the proposed workflow configuration</li> <li>Customize if needed: Adjust the workflow settings for each repository's specific needs</li> <li>Merge when ready: Merge the PRs at your own pace</li> <li>Monitor results: Once merged, AST Metrics will start analyzing your code on each commit</li> </ol>"},{"location":"ci/deploy-github-org/#tips","title":"Tips","text":"<ul> <li>Start with a small subset of repositories to test the deployment</li> <li>Review the first PR thoroughly to understand what's being added</li> <li>You can customize the workflow file in each PR before merging</li> <li>Use the interactive selection to exclude repositories that don't need metrics</li> </ul>"},{"location":"ci/deploy-github-org/#see-also","title":"See Also","text":"<ul> <li>GitHub Actions Integration</li> <li>CI Tips</li> </ul>"},{"location":"ci/github-actions/","title":"Using AST Metrics in Github action","text":"<p>You can easily integrate AST Metrics into your CI/CD pipeline.</p> <p>a Github Action is available.</p> <p>Create a <code>.github/workflows/ast-metrics.yml</code> file with the following content:</p> <pre><code>name: AST Metrics\non: [push]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n        - name: AST Metrics\n          uses: halleck45/action-ast-metrics@v1.0.2\n</code></pre> <p>Now every time you push to your repository, AST Metrics will analyze your code.</p> <p>Reports will be available on the build summary page.</p> <p>Did you know?</p> <p>You can embed directly the AST Metrics report in the web page of your github action, using the <code>$GITHUB_STEP_SUMMARY</code> environment variable.</p> <pre><code>name: AST Metrics\n(...)\nsteps:\n    - name: Adding markdown\n      run: cat ast-metrics-report.md &gt;&gt; $GITHUB_STEP_SUMMARY\n</code></pre>"},{"location":"ci/gitlab-ci/","title":"Using AST Metrics in GitLab CI","text":"<p>AST Metrics is compatible with the OpenMetrics standard. This means that you can easily integrate AST Metrics into your GitLab CI/CD pipeline.</p> <p>Create a <code>.gitlab-ci.yml</code> file with the following content:</p> <pre><code>stages:\n  - test\n\ntest:\n    stage: test\n    image: ubuntu:latest\n    script:\n        - curl -s https://raw.githubusercontent.com/Halleck45/ast-metrics/main/scripts/download.sh|sh\n        - ./ast-metrics -f --report-openmetrics=metrics.txt .\n</code></pre> <p>This configuration downloads the latest version of AST Metrics and generates an OpenMetrics report for the current directory. This report is saved in the <code>metrics.txt</code> file, and will be available as a metrics report in GitLab.</p>"},{"location":"ci/linting-architecture/","title":"Rulesets &amp; Linting","text":"<p>AST Metrics allows you to enforce rules on your codebase (Linting). You can check complexity, coupling, volume, and more.</p>"},{"location":"ci/linting-architecture/#managing-rulesets-cli","title":"Managing Rulesets (CLI)","text":"<p>The easiest way to add rules is to use the <code>ruleset</code> command. It allows you to import pre-defined sets of rules.</p>"},{"location":"ci/linting-architecture/#available-rulesets","title":"Available Rulesets","text":"<p>You can list available rulesets with:</p> <pre><code>ast-metrics ruleset list\n</code></pre> Ruleset Description architecture Architecture-related constraints (e.g., coupling) volume Volume metrics (e.g., lines of code) complexity Complexity metrics (e.g., cyclomatic complexity) golang Golang-specific best practices and API hygiene"},{"location":"ci/linting-architecture/#installing-a-ruleset","title":"Installing a Ruleset","text":"<p>To add a ruleset to your configuration:</p> <pre><code>ast-metrics ruleset add architecture\nast-metrics ruleset add volume\n</code></pre>"},{"location":"ci/linting-architecture/#detailed-rules","title":"Detailed Rules","text":""},{"location":"ci/linting-architecture/#architecture-ruleset","title":"\ud83c\udfd7\ufe0f Architecture Ruleset","text":"<p><code>ast-metrics ruleset add architecture</code></p> Rule Name Description coupling Checks for forbidden coupling between packages max_afferent_coupling Checks the afferent coupling of files/classes max_efferent_coupling Checks the efferent coupling of files/classes min_maintainability Checks the maintainability of the code no_circular_dependencies Detect circular dependencies between classes max_responsibilities Maximum number of responsibilities (LCOM) per class no_god_class Avoid God Classes (too many methods/properties)"},{"location":"ci/linting-architecture/#volume-ruleset","title":"\ud83d\udccf Volume Ruleset","text":"<p><code>ast-metrics ruleset add volume</code></p> Rule Name Description max_loc Checks the lines of code in a file max_logical_loc Checks the logical lines of code in a file max_loc_by_method Checks the lines of code by method/function max_logical_loc_by_method Checks the logical lines of code by method/function max_methods_per_class Maximum number of methods per class max_switch_cases Maximum number of cases in switch statements max_parameters_per_method Maximum number of parameters per method max_nested_blocks Maximum nesting depth of blocks max_public_methods Maximum number of public methods per class"},{"location":"ci/linting-architecture/#complexity-ruleset","title":"\ud83e\udde0 Complexity Ruleset","text":"<p><code>ast-metrics ruleset add complexity</code></p> Rule Name Description max_cyclomatic Checks the cyclomatic complexity of functions"},{"location":"ci/linting-architecture/#golang-ruleset","title":"\ud83d\udc39 Golang Ruleset","text":"<p><code>ast-metrics ruleset add golang</code></p> Rule Name Description no_package_name_in_method Do not include the package name in exported function or method identifiers max_nesting Limit nested depth of control structures (if/for/switch) max_file_size Limit file size (LOC) max_files_per_package Limit number of source files per package (excluding doc.go) slice_prealloc Check if slice preallocation is used context_missing Check if context is missing in function arguments context_ignored Check if context is ignored"},{"location":"ci/linting-architecture/#manual-configuration","title":"Manual Configuration","text":"<p>You can also manually edit the <code>.ast-metrics.yaml</code> file at the root of your project.</p> <pre><code>sources:\n  - ./internal\nexclude: []\nreports:\n  html: ./build/report\n  markdown: ./build/report.md\nrequirements:\n  rules:\n    architecture:\n      coupling:\n        forbidden:\n          - from: Controller\n            to: Repository\n          - from: Repository\n            to: Service\n      max_afferent_coupling: 10\n      max_efferent_coupling: 10\n      min_maintainability: 70\n    volume:\n      max_loc: 1000\n      max_logical_loc: 600\n      max_loc_by_method: 30\n      max_logical_loc_by_method: 20\n    complexity:\n      max_cyclomatic: 10\n    golang:\n      no_package_name_in_method: true\n      max_nesting: 4\n      max_file_size: 1000\n      max_files_per_package: 50\n      slice_prealloc: true\n      context_missing: true\n      context_ignored: true\n</code></pre> <p>Run the analysis with:</p> <pre><code>ast-metrics analyze\n</code></pre>"},{"location":"ci/tips/","title":"Tips for your CI","text":""},{"location":"ci/tips/#generate-all-reports-easily","title":"Generate all reports easily","text":"<p>AST Metrics provides a simple way to integrate code quality metrics into your CI/CD pipeline, using the <code>--ci</code> flag. This flag generates all available reports (HTML, JSON, Markdown and OpenMetrics).</p> <pre><code>ast-metrics --ci .\n</code></pre>"},{"location":"ci/tips/#deploy-to-multiple-repositories-at-once","title":"Deploy to multiple repositories at once","text":"<p>If you manage multiple repositories in a GitHub organization, you can deploy AST Metrics to all (or some) of them with a single command. See the Deploy to GitHub Organization guide for details.</p> <pre><code>ast-metrics deploy:github --token=&lt;github-token&gt; &lt;organization-name&gt;\n</code></pre> <p></p>"},{"location":"ci/tips/#comparing-with-another-branch","title":"Comparing with another branch","text":"<p>You can compare the metrics of the current branch with another branch using the <code>--compare-with</code> flag.</p> <pre><code>ast-metrics --ci --compare-with=main .\n</code></pre>"},{"location":"getting-started/","title":"Why AST Metrics?","text":"<p>TL;DR</p> <p>Just want to install? Skip to Installation \u2192</p> <p>AST Metrics goes beyond simple linting. It uses Abstract Syntax Trees (AST) and Component Graphs to analyze your code from a mathematical perspective.</p>"},{"location":"getting-started/#from-code-to-insights","title":"From Code to Insights","text":"<p>By analyzing the relationships between every file, class, and function, AST Metrics extracts the general architecture of your project. It allows you to step back and see the big picture.</p> <p>It helps you answer critical questions:</p> <ul> <li>Architecture: Is my code structured as I expect? Are there hidden dependencies?</li> <li>Risk: Which parts of the code are most likely to break?</li> <li>Coupling: How entangled are my components?</li> </ul>"},{"location":"getting-started/#how-it-works","title":"How it works","text":"<ol> <li>Parse: It reads your source code and builds an AST for each file.</li> <li>Graph: It connects all components (classes, functions) to build a dependency graph.</li> <li>Analyze: It applies graph theory and mathematical models to find patterns, clusters, and anomalies.</li> </ol> Also available as a CLI tool <p>AST Metrics can also be used directly in your terminal for quick analysis or CI/CD pipelines.</p> <p></p>"},{"location":"getting-started/#key-benefits","title":"Key Benefits","text":"<ul> <li>Language-agnostic: Works with PHP, Python, Go, Java, and more.</li> <li>Standalone: No complex setup, databases, or servers required. Just a single binary.</li> <li>Fast: Written in Go for high performance on large codebases.</li> </ul>"},{"location":"getting-started/first-execution/","title":"Running AST Metrics for the first time","text":"<p>If you haven't installed AST Metrics yet, please refer to the installation guide.</p> <p>Locate the directory where your source code is stored. For example, if you have a project in the <code>/var/www/my-project</code>  directory, you can run AST Metrics with the following command in your terminal:</p> <pre><code>ast-metrics analyze /var/www/my-project\n</code></pre> <p>This will display the CLI application, which will analyze the source code in the specified directory.</p> <p></p> <p>Navigate through the different sections using the arrow keys. You can press <code>Enter</code> to expand a section and see more details.</p> <p>To exit the application, press <code>Ctrl+C</code> or the <code>Esc</code> key.</p> <p>Note: You can search for a specific file or directory by pressing the <code>Ctrl+F</code> key and typing the name of the file or directory you want to find.</p>"},{"location":"getting-started/first-execution/#generating-an-html-report","title":"Generating an HTML Report","text":"<p>You can also generate a static HTML report to share with your team or keep as an artifact.</p> <pre><code>ast-metrics analyze /path/to/project --report-html=./report\n</code></pre> <p>This will create a <code>report</code> directory containing the full analysis.</p> <p></p>"},{"location":"getting-started/generate-reports/","title":"Generate reports","text":""},{"location":"getting-started/generate-reports/#html-report","title":"\ud83c\udf10 HTML report","text":"<p>AST Metrics can generate HTML reports. The reports provide an overview of the codebase, including:</p> <ul> <li>The number of files and directories</li> <li>The number of lines of code</li> <li>Maintainability, complexity, and risk scores</li> </ul> <p>To generate a report, run the following command in your terminal:</p> <pre><code>ast-metrics --report-html=&lt;report-directory&gt; /path/to/your/project\n</code></pre> <p>Where <code>&lt;report-directory&gt;</code> is the directory where the report will be saved.</p>"},{"location":"getting-started/generate-reports/#markdown-report","title":"\ud83d\udcc4 Markdown report","text":"<p>AST Metrics can also generate Markdown reports. The reports provide an overview of the codebase, in markdown format.</p> <p>To generate a report, run the following command in your terminal:</p> <pre><code>ast-metrics --report-markdown=&lt;report-file.md&gt; /path/to/your/project\n</code></pre> <p>Where <code>&lt;report-file.md&gt;</code> is the file where the report will be saved.</p>"},{"location":"getting-started/generate-reports/#json-report","title":"\ud83d\udcc4 JSON report","text":"<p>AST Metrics can also generate JSON reports. The reports provide an overview of the codebase, in JSON format.</p> <p>To generate a report, run the following command in your terminal:</p> <pre><code>ast-metrics --report-json=&lt;report-file.json&gt; /path/to/your/project\n</code></pre> <p>Where <code>&lt;report-file.json&gt;</code> is the file where the report will be saved.</p>"},{"location":"getting-started/generate-reports/#sarif-report","title":"\ud83d\udcc4 SARIF report","text":"<p>AST Metrics can generate SARIF (Static Analysis Results Interchange Format) reports. SARIF is a standard format for the output of static analysis tools, widely supported by security and code quality platforms like GitHub Advanced Security, Azure DevOps, and many CI/CD tools.</p> <p>To generate a SARIF report, run the following command in your terminal:</p> <pre><code>ast-metrics --report-sarif=&lt;report-file.sarif&gt; /path/to/your/project\n</code></pre> <p>Where <code>&lt;report-file.sarif&gt;</code> is the file where the report will be saved.</p>"},{"location":"getting-started/generate-reports/#use-cases","title":"Use Cases","text":"<p>SARIF reports are particularly useful for:</p> <ul> <li>GitHub Code Scanning: Upload SARIF files to GitHub to display code quality issues directly in pull requests</li> <li>CI/CD Integration: Many CI/CD platforms support SARIF for automated code quality checks</li> <li>Security Analysis: SARIF is the standard format for security scanning tools</li> <li>Tool Interoperability: Share analysis results between different static analysis tools</li> </ul>"},{"location":"getting-started/generate-reports/#openmetrics-report-gitlab-ci","title":"\ud83d\udcc4 OpenMetrics report (Gitlab CI)","text":"<p>OpenMetrics is a standard for metrics exposition. AST Metrics can generate OpenMetrics reports, which can be easily integrated into your CI/CD pipeline, like GitLab CI.</p> <p>To generate an OpenMetrics report, run the following command in your terminal:</p> <pre><code>ast-metrics --report-openmetrics=&lt;report-file.openmetrics&gt; /path/to/your/project\n</code></pre> <p>Where <code>&lt;report-file.openmetrics&gt;</code> is the file where the report will be saved.</p>"},{"location":"getting-started/install/","title":"Installing AST Metrics","text":"<p>AST Metrics is built in Golang and distributed as a single binary. It has no dependencies.</p>"},{"location":"getting-started/install/#quick-install","title":"\ud83d\ude80 Quick Install","text":"<p>Choose your preferred method below.</p>  Automatic Install (Linux/MacOS/Windows) <p>Run the following command to download the latest version:</p> <pre><code>curl -s https://raw.githubusercontent.com/Halleck45/ast-metrics/main/scripts/download.sh|sh\n</code></pre> <p>Then move the <code>./ast-metrics</code> binary to a directory in your <code>PATH</code> (e.g. <code>/usr/local/bin</code> for Linux/MacOS).</p> <p>Be careful when running scripts from the internet. Always check the content of the script before running it.</p>  Linux (Manual) <p>Download the binary for your platform (run <code>uname -m</code> in your terminal to get your architecture):</p> <ul> <li>amd64 (most common)</li> <li>arm64 (for Raspberry Pi)</li> <li>i386 (for old 32-bit systems)</li> </ul>  MacOS (Manual) <p>Download the binary for your platform (run <code>uname -m</code> in your terminal to get your architecture):</p> <ul> <li>arm64 (for Apple Silicon / M1 / M2)</li> <li>amd64 (for Intel Macs)</li> </ul>  Windows (Manual) <p>Download the executable for your platform:</p> <ul> <li>amd64 (most common)</li> <li>arm64 (for ARM)</li> <li>i386 (for old 32-bit systems)</li> </ul>  PHP Project (Composer) <p>If you are working on a PHP project, you can install AST Metrics as a dev dependency via Composer. This is the recommended way for PHP developers as it manages the binary version for you.</p> <pre><code>composer require --dev halleck45/ast-metrics\n</code></pre> <p>Then you can run it using:</p> <pre><code>php vendor/bin/ast-metrics analyze .\n</code></pre>  Go Install <p>If you have Go installed:</p> <pre><code>go install github.com/halleck45/ast-metrics@latest\n</code></pre>"},{"location":"getting-started/install/#verify-installation","title":"Verify Installation","text":"<p>Verify that the installation worked by opening a new terminal session and listing AST Metrics's available subcommands.</p> <pre><code>ast-metrics --help\n</code></pre> <p>You should see the help message with the available subcommands.</p>"},{"location":"getting-started/install/#troubleshooting","title":"Troubleshooting","text":"<p>If you get an error that the command <code>ast-metrics</code> is not found, you may need to add the directory where the binary is located to your PATH.</p>"},{"location":"getting-started/install/#updating","title":"Updating","text":"<p>Update is really easy. Just run:</p> <pre><code>ast-metrics self-update\n</code></pre>"},{"location":"getting-started/understand/","title":"Understanding the output","text":""},{"location":"getting-started/understand/#understanding-ast-metrics","title":"Understanding AST Metrics","text":"<p>You don't need a PhD in Computer Science to use AST Metrics, but understanding a few concepts will help you get the most out of it.</p>"},{"location":"getting-started/understand/#1-everything-is-a-tree-ast","title":"1. Everything is a Tree (AST)","text":"<p>First, you need to understand that any source code can be represented as a tree. This tree is called an Abstract Syntax Tree (AST).</p> <p>For example, this code:</p> <pre><code>while b \u2260 0:\n    if a &gt; b:\n        a := a - b\n    else:\n        b := b - a\nreturn a\n</code></pre> <p>Can be represented as this tree:</p> The AST of the code, from Wikipedia <p>AST Metrics analyzes this tree to calculate complexity, volume, and other code-level metrics.</p>"},{"location":"getting-started/understand/#2-the-architecture-is-a-graph","title":"2. The Architecture is a Graph","text":"<p>Just like code forms a tree, dependencies between your files form a graph.</p> <ul> <li>When Class A uses Class B, there is a link.</li> <li>When Class B uses Class C, the chain continues.</li> </ul> <p>AST Metrics analyzes this graph to find:</p> <ul> <li>Communities: Groups of classes that work together.</li> <li>Cycles: Circular dependencies that lock your system.</li> <li>Coupling: How tightly connected your components are.</li> </ul>"},{"location":"getting-started/understand/#3-from-math-to-insights","title":"3. From Math to Insights","text":"<p>By combining the AST analysis (micro-view) and the Graph analysis (macro-view), AST Metrics uses mathematical models to uncover hidden truths about your project:</p> <ul> <li>Bus Factor: Who is indispensable?</li> <li>Risk: Where are bugs likely to hide?</li> <li>Architecture Violations: Where is the code not doing what you think it is?</li> </ul> <ul> <li> <p> Ready to dive deep?</p> <p>Check out the detailed guide for every metric available in AST Metrics.</p> <p>Explore the Metrics Guide </p> </li> </ul>"},{"location":"metrics/","title":"Metrics Overview","text":"<p>AST Metrics provides a comprehensive set of metrics to help you understand the quality, structure, and health of your codebase.</p> <p>We believe that code quality is not just about style. It's about: - Reliability: How likely is it to break? - Maintainability: How easy is it to change? - Architecture: Does the code structure match your mental model?</p>"},{"location":"metrics/#available-metrics","title":"Available Metrics","text":""},{"location":"metrics/#volume-complexity","title":"\ud83d\udccf Volume &amp; Complexity","text":"<ul> <li>Volume: Lines of code, logical lines, comments. The baseline for everything.</li> <li>Cyclomatic Complexity: How many paths through your code?</li> <li>Maintainability Index: A global score for code health.</li> <li>Risk Score: Complexity \u00d7 Churn. Where are the bugs hiding?</li> </ul>"},{"location":"metrics/#coupling-cohesion","title":"\ud83d\udd17 Coupling &amp; Cohesion","text":"<ul> <li>Coupling &amp; Instability: How classes depend on each other.</li> <li>LCOM4: Do methods in a class belong together?</li> </ul>"},{"location":"metrics/#architecture-team","title":"\ud83c\udfd7\ufe0f Architecture &amp; Team","text":"<ul> <li>Community Detection: The natural structure of your code.</li> <li>Bus Factor: Knowledge distribution and risk.</li> <li>Architecture Map: Visualizing the system.</li> </ul>"},{"location":"metrics/architecture-map/","title":"Architecture Map","text":""},{"location":"metrics/architecture-map/#what-it-reveals","title":"What It Reveals","text":"<p>The Architecture Map shows you the truth about your code structure.</p> <p>Developers often believe their architecture follows a certain pattern: \"We have clean layers,\" \"Our domain is isolated,\" \"We follow hexagonal architecture.\" But code tells a different story.</p> <p>The Architecture Map doesn't lie. It reveals:</p> <ul> <li>The real dependencies, not the intended ones</li> <li>Hidden coupling between modules you thought were independent</li> <li>Circular dependencies that make refactoring painful</li> <li>Layer violations where low-level code depends on high-level code</li> </ul> <p></p>"},{"location":"metrics/architecture-map/#what-to-look-for","title":"What to Look For","text":"<p>Vertical Strata: If your application is well-layered, you'll see clear vertical levels. High-level components (controllers, UI) at the top, low-level utilities at the bottom.</p> <p>Flat Horizontal Graph: Everything at the same level means your code lacks proper separation of concerns. No clear boundaries between layers.</p> <p>Cycles: Circular dependencies appear as loops. These create rigid, hard-to-test code.</p> <p>[!TIP] If you think you have a layered architecture but the map shows a flat horizontal line, your code is not as decoupled as you think. The graph doesn't lie.</p>"},{"location":"metrics/architecture-map/#how-it-works","title":"How It Works","text":""},{"location":"metrics/architecture-map/#1-community-detection","title":"1. Community Detection","text":"<p>Instead of showing thousands of individual classes, AST Metrics groups them into Communities using the Louvain Algorithm.</p> <p>A Community is a cluster of classes that interact more with each other than with the rest of the system.</p> <p></p>"},{"location":"metrics/architecture-map/#2-dependency-layering","title":"2. Dependency Layering","text":"<p>Once communities are identified, the graph arranges them based on Dependency Degree:</p> <ul> <li>Top Layers: High-level components (Controllers, Presentation). They depend on many things but are rarely depended upon.</li> <li>Bottom Layers: Low-level components (Utilities, Core Domain, Infrastructure). Used by everyone but depend on few.</li> </ul> <p>The vertical position is purely mathematical, based on how many dependencies point to vs from each component.</p>"},{"location":"metrics/bus-factor/","title":"Bus Factor","text":""},{"location":"metrics/bus-factor/#what-is-it","title":"What is it?","text":"<p>The Bus Factor is a risk metric that answers: \"How many team members have to be hit by a bus for the project to stall?\"</p> <p>It estimates the concentration of knowledge in your codebase.</p> <ul> <li>Bus Factor = 1: Critical Risk. Only one person understands a key part of the system. If they leave, that knowledge is lost.</li> <li>Bus Factor = High: Healthy. Knowledge is shared among multiple developers.</li> </ul>"},{"location":"metrics/bus-factor/#how-is-it-calculated","title":"How is it calculated?","text":"<p>AST Metrics analyzes the Git history (authorship of lines). 1.  It calculates the \"ownership\" of each file (who wrote the most lines). 2.  It aggregates this ownership by Community (not just folders). 3.  If a community is 80%+ owned by a single person, the Bus Factor for that community is 1.</p>"},{"location":"metrics/bus-factor/#how-to-improve-it","title":"How to improve it?","text":"<p>Share Knowledge</p> <p>If you have a low Bus Factor:</p> <ol> <li>Pair Programming: Have the expert pair with others on that component.</li> <li>Code Reviews: Ensure others review changes to critical files.</li> <li>Documentation: Write down the implicit knowledge.</li> </ol>"},{"location":"metrics/community-detection/","title":"Community Detection","text":""},{"location":"metrics/community-detection/#what-is-it","title":"What is it?","text":"<p>Your code naturally forms \"neighborhoods\" or communities. Even if you didn't plan it, some classes talk to each other more than others.</p> <p>AST Metrics uses the Louvain Algorithm (a graph clustering algorithm) to detect these communities automatically based on the dependency graph.</p>"},{"location":"metrics/community-detection/#why-it-matters","title":"Why it matters?","text":"<ul> <li>Reality Check: Does the code structure match your folder structure?</li> <li>Leak Detection: Are \"Domain\" classes talking to \"Infrastructure\" classes when they shouldn't?</li> <li>Modularity: Helps identify natural boundaries for microservices or modules.</li> </ul>"},{"location":"metrics/community-detection/#interpreting-the-results","title":"Interpreting the Results","text":""},{"location":"metrics/community-detection/#purity","title":"Purity","text":"<p>AST Metrics calculates the \"purity\" of a community by checking if its members belong to the same namespace.</p> <ul> <li>High Purity: The community corresponds to a namespace. Good modularity.</li> <li>Low Purity: The community is a mix of unrelated namespaces. This often indicates Spaghetti Architecture or hidden dependencies.</li> </ul>"},{"location":"metrics/community-detection/#modularity-score","title":"Modularity Score","text":"<p>A global score (0-1) indicating how well the network divides into modular communities. High modularity means dense connections within modules and sparse connections between them.</p>"},{"location":"metrics/coupling/","title":"Coupling &amp; Instability","text":"<p>Coupling measures how dependent classes are on each other. High coupling makes code rigid and fragile.</p>"},{"location":"metrics/coupling/#afferent-coupling-ca","title":"Afferent Coupling (Ca)","text":"<p>\"Who uses me?\" - The number of classes that depend on this class. - High Ca: This class is Critical or Responsible. - Examples: Core domain entities, Utility classes, Shared libraries. - Risk: If you change this class, you might break many things (high impact).</p>"},{"location":"metrics/coupling/#efferent-coupling-ce","title":"Efferent Coupling (Ce)","text":"<p>\"Who do I use?\" - The number of classes this class depends on. - High Ce: This class is Dependent. - Examples: Orchestrators, Facades. - Risk: This class is fragile because it breaks if any of its dependencies change.</p>"},{"location":"metrics/coupling/#instability-i","title":"Instability (I)","text":"<p>Instability is a ratio between 0 and 1 derived from coupling.</p> <p>$$ I = \\frac{Ce}{Ca + Ce} $$</p>"},{"location":"metrics/coupling/#0-stable","title":"0: Stable","text":"<p>I am used by many, but I use no one. - Hard to change because many depend on it. - Should be very robust and abstract. - Example: <code>String</code>, <code>Integer</code>, Core Interfaces.</p>"},{"location":"metrics/coupling/#1-unstable","title":"1: Unstable","text":"<p>I use many, but nobody uses me. - Easy to change because nobody depends on it. - Can be concrete and volatile. - Example: Controllers, CLI Commands, Scripts.</p> <p>The Stable Dependencies Principle (SDP)</p> <p>Dependencies should point in the direction of stability. A component should only depend on components that are more stable than itself.</p> <p>Unstable (Variable) $\\rightarrow$ Stable (Abstract)</p>"},{"location":"metrics/cyclomatic-complexity/","title":"Cyclomatic Complexity","text":""},{"location":"metrics/cyclomatic-complexity/#what-is-it","title":"What is it?","text":"<p>Cyclomatic Complexity (often denoted as $V(G)$) measures the number of independent paths through your code. Think of your code as a maze. Every control structure adds a turn or a branch in the maze.</p> <p>It counts: - <code>if</code>, <code>else</code>, <code>elseif</code> - <code>while</code>, <code>for</code>, <code>foreach</code> - <code>case</code>, <code>default</code> - <code>catch</code> - Boolean operators (<code>&amp;&amp;</code>, <code>||</code>)</p> <ul> <li>Complexity = 1: A straight road. No decisions.</li> <li>Complexity = 5: A small neighborhood with a few turns.</li> <li>Complexity = 50: A chaotic bowl of spaghetti.</li> </ul>"},{"location":"metrics/cyclomatic-complexity/#why-it-matters","title":"Why it matters?","text":"<p>High complexity means: 1.  Harder to understand: You can't hold the logic in your head. 2.  Harder to test: You need at least one test case per path to cover everything. A complexity of 10 means you need at least 10 unit tests to achieve 100% branch coverage.</p>"},{"location":"metrics/cyclomatic-complexity/#thresholds","title":"Thresholds","text":"<p>Keep it under 10.</p> Score Risk Recommendation 1-10 Low Simple code. Good. 11-20 Moderate More complex. Needs thorough testing. 21-50 High High risk. Refactor. Split into smaller methods. &gt; 50 Critical Untestable. Rewrite."},{"location":"metrics/cyclomatic-complexity/#how-to-reduce-it","title":"How to reduce it?","text":"<ul> <li>Extract Method: Take a complex part of the logic and move it to a new private method.</li> <li>Early Return: Use <code>return</code> early to avoid deep nesting of <code>if/else</code>.</li> <li>Strategy Pattern: Replace complex <code>switch</code> statements with polymorphism.</li> </ul>"},{"location":"metrics/lcom4/","title":"LCOM4 (Lack of Cohesion of Methods)","text":""},{"location":"metrics/lcom4/#what-is-it","title":"What is it?","text":"<p>LCOM4 measures how well the methods in a class belong together. It checks if methods use the same fields.</p> <p>It answers the question: \"Is this class doing one thing, or multiple unrelated things?\"</p>"},{"location":"metrics/lcom4/#how-it-works","title":"How it works","text":"<p>Imagine a graph where: - Nodes are methods. - Edges connect methods if they access the same field or call each other.</p> <p>LCOM4 is the number of connected components in this graph.</p> <ul> <li>LCOM4 = 1: Cohesive. All methods are related. The class acts as a single unit.</li> <li>LCOM4 &gt; 1: Not Cohesive. The class is doing too many things. It might be two or more classes stuck together.</li> <li>LCOM4 = 0: Empty class or no methods.</li> </ul>"},{"location":"metrics/lcom4/#visualizing-lcom4","title":"Visualizing LCOM4","text":"<p>Imagine drawing lines between methods and the fields they use. - If everything is connected, LCOM4 = 1. - If you have two separate islands of connections, LCOM4 = 2.</p>"},{"location":"metrics/lcom4/#how-to-fix-it","title":"How to fix it?","text":"<p>Refactoring Opportunity</p> <p>If LCOM4 &gt; 1, you can usually split the class into two separate classes without breaking anything.</p> <ol> <li>Identify the \"islands\" of methods/fields.</li> <li>Extract each island into a new class.</li> <li>Inject the new classes into the original one (or replace usages).</li> </ol>"},{"location":"metrics/maintainability-index/","title":"Maintainability Index","text":""},{"location":"metrics/maintainability-index/#what-is-it","title":"What is it?","text":"<p>The Maintainability Index (MI) is a composite score (0-100) designed to indicate how maintainable (easy to support and change) the source code is.</p> <p>It is calculated using a polynomial equation that combines: - Halstead Volume: Measures the size of the implementation (vocabulary and length). - Cyclomatic Complexity: Measures the control flow complexity. - Lines of Code: Measures the physical size.</p>"},{"location":"metrics/maintainability-index/#how-to-read-it","title":"How to read it?","text":"<p>It gives you a single number to judge a file's health at a glance.</p> Score Rating Meaning 85-100 \ud83d\udfe2 A Excellent. Easy to maintain. 65-84 \ud83d\udfe1 B Good. Moderate maintainability. &lt; 65 \ud83d\udd34 C Bad. Hard to maintain. Consider refactoring."},{"location":"metrics/maintainability-index/#limitations","title":"Limitations","text":"<p>Context matters</p> <p>A complex algorithm (like a parser or a mathematical computation) might naturally have a lower score. But for standard business logic, controllers, or services, you should aim for green.</p> <p>The Maintainability Index is best used as a trend metric. If it drops over time, your technical debt is increasing.</p>"},{"location":"metrics/risk/","title":"Risk Score","text":""},{"location":"metrics/risk/#what-is-it","title":"What is it?","text":"<p>The Risk score is the probability that the code needs refactoring.</p> <p>It is a composite metric that identifies \"Hotspots\" in your codebase.</p>"},{"location":"metrics/risk/#how-is-it-calculated","title":"How is it calculated?","text":"<p>The Risk score is calculated based on two main factors: 1.  Complexity: How hard is the code to understand? (Cyclomatic Complexity) 2.  Activity: How often is this code changed? (Git Churn)</p> <p>$$ Risk = Complexity \\times Churn $$</p>"},{"location":"metrics/risk/#why-it-matters","title":"Why it matters?","text":"<ul> <li>Complex code that never changes is not a high risk. It works, leave it alone.</li> <li>Simple code that changes often is fine.</li> <li>Complex code that changes often is a Time Bomb. This is where bugs are most likely to be introduced.</li> </ul>"},{"location":"metrics/risk/#how-to-use-it","title":"How to use it?","text":"<p>In the CLI application, look at the <code>Top candidates for refactoring</code> section. These are the files with the highest Risk score.</p> <p></p> <p>Prioritize Refactoring</p> <p>Don't just refactor everything. Focus your energy on the High Risk files first. These will give you the best Return on Investment (ROI).</p>"},{"location":"metrics/volume/","title":"Volume Metrics","text":""},{"location":"metrics/volume/#what-is-it","title":"What is it?","text":"<p>Volume metrics are the simplest form of measurement: counting things.</p> <ul> <li>LOC (Lines of Code): The total number of lines in a file.</li> <li>LLOC (Logical Lines of Code): The number of executable statements (ignoring comments and whitespace).</li> <li>CLOC (Comment Lines of Code): The number of comment lines.</li> </ul>"},{"location":"metrics/volume/#why-it-matters","title":"Why it matters?","text":"<p>It might seem basic, but Volume is the metric that correlates most strongly with defects. Statistically, the more code you have, the more bugs you will have. It's a law of nature in software engineering.</p> <p>Use Volume as a baseline</p> <p>A class with high complexity is bad. A huge class with high complexity is worse. Always look at other metrics in the context of volume.</p>"},{"location":"metrics/volume/#how-to-read-it","title":"How to read it?","text":"<ul> <li>High Volume + High Complexity: \ud83d\udea9 Red Flag. Hard to maintain, prone to bugs.</li> <li>High Volume + Low Complexity: Often data structures or configuration. Usually safe.</li> <li>Low Volume: Generally safe, unless it's \"code golf\" (overly clever one-liners).</li> </ul>"}]}